{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c68f8b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aiden/Dropbox/Mac/Desktop/keras_nlp_ywj/ch8_RNN'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4911bad",
   "metadata": {},
   "source": [
    "# 1. 임의의 입력 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f7c900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65fbc656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.1, 4.2, 1.5, 1.1, 2.8],\n",
       " [1.0, 3.1, 2.5, 0.7, 1.1],\n",
       " [0.3, 2.1, 1.5, 2.1, 0.1],\n",
       " [2.2, 1.4, 0.5, 0.9, 1.1]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN과 LSTM을 테스트하기 위한 임의의 입력을 만듭니다.\n",
    "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
    "\n",
    "print(np.shape(train_X))\n",
    "train_X"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d3223d4",
   "metadata": {},
   "source": [
    "위 입력은 단어 벡터의 차원은 5이고, 문장의 길이가 4인 경우를 가정한 입력입니다. \n",
    "다시 말해 4개의 단어(4번의 시점:timesteps)이 존재하고, 각 시점마다 5차원의 단어 벡터가 입력으로 사용됩니다. 그런데 앞서 RNN은 2D 텐서가 아니라 3D 텐서를 입력을 받는다고 언급한 바 있습니다. 즉, 위에서 만든 2D 텐서를 3D 텐서로 변경합니다. 이는 배치 크기 1을 추가해줌으로써 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3e2811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.1, 4.2, 1.5, 1.1, 2.8],\n",
       "        [1. , 3.1, 2.5, 0.7, 1.1],\n",
       "        [0.3, 2.1, 1.5, 2.1, 0.1],\n",
       "        [2.2, 1.4, 0.5, 0.9, 1.1]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape)\n",
    "train_X  # 입력 텐서는 (1, 4, 5) 크기를 가지는 3D 텐서"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77e7c299",
   "metadata": {},
   "source": [
    "(batch_size, timesteps, input_dim)에 해당되는 (1, 4, 5)의 크기를 가지는 3D 텐서가 생성되었습니다. \n",
    "batch_size는 한 번에 RNN이 학습하는 데이터의 양을 의미하지만, 여기서는 샘플이 1개 밖에 없으므로 batch_size는 1입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7279ec",
   "metadata": {},
   "source": [
    "# 2. SimpleRNN 이해하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac35e23b",
   "metadata": {},
   "source": [
    "위에서 생성한 데이터를 SimpleRNN의 입력으로 사용하여 SimpleRNN의 출력값을 이해해보겠습니다. SimpleRNN에는 여러 인자가 있으며 대표적인 인자로 return_sequences와 return_state가 있습니다. 기본값으로는 둘 다 False로 지정되어져 있으므로 별도 지정을 하지 않을 경우에는 False로 처리됩니다. 우선, 은닉 상태의 크기를 3으로 지정하고, 두 인자 값이 모두 False일 때의 출력값을 보겠습니다.\n",
    "\n",
    "앞으로의 실습에서 SimpleRNN을 매번 재선언하므로 은닉 상태의 값 자체는 매번 초기화되어 이전 출력과 값의 일관성은 없습니다. \n",
    "그래서 출력값 자체보다는 해당 값의 크기(shape)에 주목해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "908f1707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.9969979  -0.47803527 -0.9990314 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# 은닉 상태의 크기를 3으로 지정\n",
    "rnn = SimpleRNN(3)\n",
    "# rnn = SimpleRNN(3, return_sequences=False, return_state=False)와 동일.\n",
    "hidden_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d767f98",
   "metadata": {},
   "source": [
    "(1, 3) 크기의 텐서가 출력되는데, 이는 마지막 시점의 은닉 상태입니다. 은닉 상태의 크기를 3으로 지정했음을 주목합시다.\n",
    "return_sequences=False -> 마지막 시점의 은닉 상태만 출력.\n",
    "\n",
    "이번에는 return_sequences를 True로 지정하여 모든 시점의 은닉 상태를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e777690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : {} tf.Tensor(\n",
      "[[[-0.24955149 -0.3409324   0.9839179 ]\n",
      "  [ 0.7024925  -0.9878981   0.91960406]\n",
      "  [ 0.13021053 -0.99412835 -0.50716364]\n",
      "  [ 0.14922251 -0.9886263   0.9900323 ]]], shape=(1, 4, 3), dtype=float32)\n",
      "shape:  (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True)\n",
    "hidden_states = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}', hidden_states)\n",
    "print('shape: ', hidden_states.shape)\n",
    "# -> 모든 시점에 대해 은닉 상태의 값인 (1, 4, 3)크기의 텐서 출력"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8faf2651",
   "metadata": {},
   "source": [
    "return_state=True -> (return_sequences의 True/False 여부와 상관없이) 마지막 시점의 은닉 상태를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3708b59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.999782    0.9857592  -0.99005616]\n",
      "  [ 0.9996902   0.995894   -0.9981255 ]\n",
      "  [ 0.99361676  0.9923747  -0.9990918 ]\n",
      "  [ 0.97182816  0.989509   -0.9983537 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[ 0.97182816  0.989509   -0.9983537 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# return_sequences=True, return_state=True인 경우\n",
    "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ac273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcba3b56",
   "metadata": {},
   "source": [
    "# 3. LSTM 이해하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58a2ad11",
   "metadata": {},
   "source": [
    "실제로 SimpleRNN이 사용되는 경우는 거의 없습니다. 이보다는 LSTM이나 GRU을 주로 사용하는데, \n",
    "이번에는 임의의 입력에 대해서 LSTM을 사용할 경우를 보겠습니다. \n",
    "우선 return_sequences를 False로 두고, return_state가 True인 경우를 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d88e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[ 0.20844159 -0.00946012 -0.06378686]], shape: (1, 3)\n",
      "last hidden state : [[ 0.20844159 -0.00946012 -0.06378686]], shape: (1, 3)\n",
      "last cell state : [[ 1.4330432  -0.03410259 -0.21709146]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fb647ff",
   "metadata": {},
   "source": [
    "이번에는 SimpleRNN 때와는 달리, 세 개의 결과를 반환합니다. \n",
    "return_sequences가 False이므로 우선 첫번째 결과는 마지막 시점의 은닉 상태입니다. \n",
    "그런데 LSTM이 SimpleRNN과 다른 점은 return_state를 True로 둔 경우에는 마지막 시점의 은닉 상태뿐만 아니라 \n",
    "셀 상태까지 반환한다는 점입니다. \n",
    "\n",
    "이번에는 return_sequences를 True로 바꿔보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13e8fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[-0.10702933  0.05555321 -0.3235023 ]\n",
      "  [-0.22836396  0.12103008 -0.19993871]\n",
      "  [-0.33012635  0.09225787 -0.25593245]\n",
      "  [-0.48163924  0.0623228   0.15094148]]], shape: (1, 4, 3)\n",
      "last hidden state : [[-0.48163924  0.0623228   0.15094148]], shape: (1, 3)\n",
      "last cell state : [[-0.86355776  0.19970028  0.46225145]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_hidden_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_hidden_state, last_hidden_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa382947",
   "metadata": {},
   "source": [
    "return_state가 True이므로 두번째 출력값이 마지막 은닉 상태, 세번째 출력값이 마지막 셀 상태인 것은 변함없지만 \n",
    "return_sequences가 True이므로 첫번째 출력값은 모든 시점의 은닉 상태가 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d128b7b",
   "metadata": {},
   "source": [
    "# 4. Bidirectional LSTM 이해하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7503d211",
   "metadata": {},
   "source": [
    "난이도를 조금 올려서 양방향 LSTM의 출력값을 확인해보겠습니다. \n",
    "\n",
    "return_sequences가 True인 경우와 False인 경우에 대해서 은닉 상태의 값이 어떻게 바뀌는지 직접 비교하기 위해서 \n",
    "이번에는 출력되는 은닉 상태의 값을 고정시켜주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e504e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_init = tf.keras.initializers.Constant(value=0.1)\n",
    "b_init = tf.keras.initializers.Constant(value=0)\n",
    "r_init = tf.keras.initializers.Constant(value=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00c6c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 return_sequences가 False이고, return_state가 True인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed15b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[0.6303138 0.6303138 0.6303138 0.7038734 0.7038734 0.7038734]], shape: (1, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, \\\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6fc7e6f",
   "metadata": {},
   "source": [
    "첫번째 출력값의 크기가 (1, 6)인 것에 주목합시다. return_sequences가 False인 경우 \n",
    "\n",
    "정방향 LSTM의 마지막 시점의 은닉 상태와 \n",
    "역방향 LSTM의 첫번째 시점의 은닉 상태가 연결된 채 반환되기 때문입니다. 그림으로 표현하면 아래와 같이 연결되어 다음층에서 사용됩니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "33b195c3",
   "metadata": {},
   "source": [
    "마찬가지로 return_state가 True인 경우에 반환한 은닉 상태의 값인 forward_h와 backward_h는 각각 정방향 LSTM의 마지막 시점의 은닉 상태와 역방향 LSTM의 첫번째 시점의 은닉 상태값입니다. 그리고 이 두 값을 연결한 값이 hidden_states에 출력되는 값입니다. \n",
    "\n",
    "이를 이용한 실습은 'RNN을 이용한 텍스트 분류 챕터'에서의 한국어 스팀 리뷰 분류하기 실습( https://wikidocs.net/94748 )을 참고하세요."
   ]
  },
  {
   "cell_type": "raw",
   "id": "02ce5c65",
   "metadata": {},
   "source": [
    "정방향 LSTM의 마지막 시점의 은닉 상태값과 역방향 LSTM의 첫번째 은닉 상태값을 기억해둡시다.\n",
    "- 정방향 LSTM의 마지막 시점의 은닉 상태값 : [0.6303138 0.6303138 0.6303138]\n",
    "- 역방향 LSTM의 첫번째 시점의 은닉 상태값 : [0.7038734 0.7038734 0.7038734]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc53ffe0",
   "metadata": {},
   "source": [
    "현재 은닉 상태의 값을 고정시켜두었기 때문에 return_sequences를 True로 할 경우, 출력이 어떻게 바뀌는지 비교가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba14bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
      "  [0.55111325 0.55111325 0.55111325 0.58863586 0.58863586 0.58863586]\n",
      "  [0.59115744 0.59115744 0.59115744 0.3951699  0.3951699  0.3951699 ]\n",
      "  [0.6303138  0.6303138  0.6303138  0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, \\\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "역방향 LSTM의 첫번째 시점의 은닉 상태는 더 이상 정방향 LSTM의 마지막 시점의 은닉 상태와 연결되는 것이 아니라 \n",
    "정방향 LSTM의 첫번째 시점의 은닉 상태와 연결됩니다.\n",
    "\n",
    "그림으로 표현하면 다음과 같이 연결되어 다음층의 입력으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c4e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35074718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaad511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638262e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5267b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
